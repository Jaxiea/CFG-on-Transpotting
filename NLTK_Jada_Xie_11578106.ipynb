{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words is: 1073\n",
      "The vocabulary size is: 462\n",
      "The number of sentences is: 108\n",
      "The number of exclamatory sentences is: 11\n",
      "The number of interrogative sentences is: 5\n",
      "The most frequent 8 words are: [('the', 54), ('ah', 42), ('tae', 30), ('fuckin', 28), ('a', 25), ('ay', 19), ('he', 18), ('his', 18)]\n",
      "Bonus: The number of sentences that contains the word stem fuck is: 30\n"
     ]
    }
   ],
   "source": [
    "raw = open('Trainspotting by Irving Welsh - First 1100 words.txt').read()\n",
    "i = 0\n",
    "m = 0 \n",
    "n = 0 #counters\n",
    "\n",
    "#trimming and cleaning the text\n",
    "raw = raw[336:len(raw)-1] #trimming\n",
    "raw = raw.replace(\"\\\\\", \"\")\n",
    "\n",
    "  \n",
    "#sentences    \n",
    "s_tokens = nltk.sent_tokenize(raw)\n",
    "sentences = [s.lower() for s in s_tokens]\n",
    "\n",
    "for s in sentences:\n",
    "    if \"fuck\" in s:\n",
    "        i = i + 1\n",
    "    if \"!\" in s:\n",
    "        m = m + 1\n",
    "    if \"?\" in s:\n",
    "        n = n + 1\n",
    "\n",
    "#words and vocab\n",
    "w_tokens = nltk.word_tokenize(raw)\n",
    "words = [word.lower() for word in w_tokens if word.isalpha()]\n",
    "\n",
    "print(\"The number of words is:\", len(words))\n",
    "\n",
    "vocab = sorted(set(words))\n",
    "print(\"The vocabulary size is:\", len(vocab))\n",
    "print(\"The number of sentences is:\", len(sentences))\n",
    "print(\"The number of exclamatory sentences is:\", m)\n",
    "print(\"The number of interrogative sentences is:\", n)\n",
    "\n",
    "fdist1 = nltk.FreqDist(words)\n",
    "print(\"The most frequent 8 words are:\", fdist1.most_common(8))\n",
    "\n",
    "print(\"Bonus: The number of sentences that contains the word stem fuck is:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser\n",
    "\n",
    "def check_sentence(parser, sentence):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Checking if provided sentence matches the grammar:\")\n",
    "    print(sentence)\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.split()\n",
    "    tree_found = False\n",
    "    results = parser.parse(sentence)\n",
    "    for tree in results:\n",
    "        tree_found = True\n",
    "        print(tree)\n",
    "    if not tree_found:\n",
    "        print(sentence, \"Does not match the provided grammar.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return tree_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Checking if provided sentence matches the grammar:\n",
      "he wis bringing me doon\n",
      "(S\n",
      "  (NP (ProN he))\n",
      "  (VP (AuxV wis) (VP (V bringing) (NP (ProN me)) (Adv doon))))\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_1 = CFG.fromstring(\"\"\"\n",
    "\n",
    "  S -> NP VP\n",
    "  S -> VP NP\n",
    "  S -> NP CP NP\n",
    "  S -> VP NP VP\n",
    "  S -> NP VP CP VP\n",
    "  S -> NP CP NP VP\n",
    "  S -> CP NP VP NP\n",
    "  S -> NP CP NP CP NP\n",
    "  \n",
    "  S -> ProN\n",
    "  S -> InterJ\n",
    "  S -> WH AuxV NP\n",
    "  S -> PP NP\n",
    "\n",
    "  Comp -> N N\n",
    "  \n",
    "  NP -> Det N\n",
    "  NP -> Det N Adv\n",
    "  NP -> Det AdjP N\n",
    "\n",
    "  AdjP -> Adj Adj\n",
    "  AdjP -> Adv Adj\n",
    "  AdjP -> Adj Adj CP Adj\n",
    "  \n",
    "  NP -> ProN \n",
    "  NP -> AdjP ProN\n",
    "  NP -> AdjP N\n",
    "  NP -> AdjP Comp\n",
    "  NP -> ProN N \n",
    "  NP -> ProN VP\n",
    " \n",
    "  NP -> Adv AdjP N\n",
    "  \n",
    "  NP -> Adv NP PP\n",
    "\n",
    "  VP -> CP VP PP \n",
    "  VP -> AuxV VP\n",
    "  VP -> AuxV V\n",
    "  VP -> AuxV NP\n",
    "  VP -> AuxV AdjP\n",
    "  VP -> AuxV AdjP PP\n",
    "  VP -> AuxV AdjP IP\n",
    "  \n",
    "  VP -> V NP\n",
    "  VP -> V NP VP\n",
    "  VP -> V NP CP NP\n",
    "  VP -> V NP PP CP NP\n",
    "  VP -> V NP CP NP PP\n",
    "  VP -> AuxV VP PP\n",
    "  VP -> V NP PP\n",
    "  VP -> V ProN\n",
    "  VP -> V ProN Adj\n",
    "  VP -> V ProN NP\n",
    "  VP -> V NP Adv\n",
    "  VP -> AuxV Adv NP\n",
    "  VP -> V AdjP VP\n",
    "  \n",
    "  VP -> V PP \n",
    "  VP -> V PP NP\n",
    "  VP -> V PP VP\n",
    "  VP -> V Prep CP NP\n",
    "  VP -> V Prep PP\n",
    "  VP -> V Adv VP\n",
    "  VP -> V Adv PP\n",
    "  VP -> Adv V Prep PP\n",
    "  VP -> Adv VP\n",
    "  VP -> V Prep AdjP\n",
    "  VP -> V CP NP VP\n",
    "  \n",
    "  VP -> V IP\n",
    "  VP -> AuxV IP\n",
    "  IP -> IPrep VP\n",
    "  IP -> IPrep V\n",
    "  IP -> Adv IP\n",
    "  \n",
    "  PP -> Prep N\n",
    "  PP -> Prep NP\n",
    "  PP -> Adv Prep NP\n",
    "  PP -> Prep Comp\n",
    "  PP -> AdjP Adv NP\n",
    "  PP -> IP CP VP\n",
    "  \n",
    "  CP -> CC\n",
    "  CP -> Adv CC\n",
    "  CP -> CC CC\n",
    "  \n",
    "  \n",
    "  Det -> \"a\" | \"an\" | \"any\" | \"the\" | \"that\" | \"one\"\n",
    "  WH -> \"what\" | \"whit\" | \"whae\" | \"when\"\n",
    "  Prep -> \"wi\" | \"fir\" | \"withoot\" | \"aboot\" | \"against\" | \"at\" | \"before\" | \"by\" | \"in\" | \"fuckin\" | \"intae\" | \"later\" | \"oan\" | \"ower\" | \"tae\" | \"than\" | \"through\" | \"up\" | \"ay\"\n",
    "  IPrep -> \"tae\"\n",
    "  AuxV -> \"will\" | \"would\" | \"have\" | \"wouldnae\" | \"wisnae\" | \"wis\" | \"wir\" | \"wid\" | \"am\" | \"widae\" | \"were\" | \"are\" | \"be\" | \"been\" | \"did\" | \"didnae\" | \"dinnae\" | \"do\" | \"does\" | \"hud\" | \"hudnae\" | \"huv\" | \"is\" | \"has\" \n",
    "  V ->  \"haud\" | \"gitting\" | \"supposed\" | \"opening\" | \"notice\" | \"add\" | \"asks\" | \"based\" | \"baws\" | \"beating\" | \"breathing\" | \"bringing\" | \"building\" | \"bulging\" | \"call\" | \"called\" | \"came\" | \"charged\" | \"comin\" | \"congregated\" | \"covered\" | \"craned\" | \"done\" | \"doubt\" | \"draggin\" | \"emphasise\" | \"faster\" | \"feel\" | \"fling\" | \"flings\" | \"focusing\" | \"freezing\" | \"harassing\" | \"hing\" | \"introducing\" | \"knowing\" | \"lashing\" | \"looking\" | \"saying\" | \"shaking\" | \"sitting\" | \"standing\" | \"sticking\" | \"straining\" | \"suffering\" | \"trembling\" | \"willing\" | \"gittin\" | \"lovin\" | \"makin\" | \"pleadin\" | \"sayin\" | \"standin\" | \"sufferin\" | \"takin\" | \"tryin\" | \"walkin\" | \"wastin\" | \"fuck\" | \"gasped\" | \"gestured\" | \"gie\" | \"git\" | \"go\" | \"goat\" | \"happens\" | \"hit\" | \"hope\" | \"keep\" | \"ken\" | \"kent\" | \"leave\" | \"let\" | \"live\" | \"look\" | \"looked\" | \"looks\" | \"meant\" | \"move\" | \"moves\" | \"muttered\" | \"need\" | \"piled\" | \"played\" | \"pokes\" | \"preferred\" | \"protested\" | \"raises\" | \"remember\" | \"rests\" | \"sais\" | \"saw\" | \"scored\" | \"see\" | \"seem\" | \"seemed\" | \"set\" | \"shouted\" | \"shouts\" | \"smash\" | \"snapped\" | \"snarled\" | \"sped\" | \"splatterd\" | \"stares\" | \"started\" | \"stoaped\" | \"switched\" | \"take\" | \"think\" | \"tried\" | \"turns\" | \"ur\" | \"walk\" | \"want\" | \"wanted\" | \"wants\" | \"watch\" | \"went\" | \"involved\" \n",
    "  Adj -> \"some\" | \"moosey-faced\" | \"aqua\" | \"sure\" | \"aw\" | \"money-grabbin\" | \"young\" | \"advance\" | \"amused\" | \"another\" | \"arrogant\" | \"auld\" | \"back\" | \"better\" | \"black\" | \"chuffed\" | \"crapping\" | \"crusing\" | \"dandy\" | \"dastardly\" | \"doss\" | \"dramatic\" | \"enough\" | \"every\" | \"fat\" | \"feart\" | \"few\" | \"fifty\" | \"first\" | \"irritating\" | \"fuckin\" | \"fucked\" | \"good\" | \"here\" | \"hostile\" | \"hunted\" | \"intense\" | \"irresistible\" | \"lazy\" | \"long\" | \"longer\" | \"lowest\" | \"lucky\" | \"mair\" | \"measley\" | \"middle\" | \"nae\" | \"next\" | \"obligatory\" | \"other\" | \"petty\" | \"poignant\" | \"poxy\" | \"purple\" | \"rich\" | \"right\" | \"same\" | \"serious\" | \"sick\" | \"side\" | \"silent\" | \"smart\" | \"such\" | \"supposed\" | \"this\" | \"trivial\" | \"weak\" | \"wee\"\n",
    "  ProN -> \"another\" | \"what\" | \"jeanclaude\" | \"youse\" | \"yir\" | \"ye\" | \"ya\" | \"white\" | \"wester\" | \"ah\" | \"aye\" | \"chancey\" | \"hailes\" | \"he\" | \"him\" | \"his\" | \"hissel\" | \"it\" | \"johnny\" | \"ma\" | \"maist\" | \"mclean\" | \"mcleans\" | \"me\" | \"mines\" | \"nae\" | \"oor\" | \"porty\" | \"raymie\" | \"rents\" | \"ritz\" | \"seeker\" | \"si\" | \"sickboy\" | \"simon\" | \"simone\" | \"mothersuperior\" | \"swan\" | \"swanney\" | \"that\" | \"them\" | \"there\" | \"these\" | \"they\" | \"thir\" | \"thistle\" | \"um\" | \"urn\" | \"us\" | \"jeanclaudevandamme\" | \"we\"\n",
    "  N -> \"jackjones\" | \"leithwalk\" | \"wey\" | \"windae\" | \"flat-top\" | \"shell-suit\" | \"swedgin\" | \"opening\" | \"yards\" | \"withdrawal\" | \"way\" | \"ain\" | \"animal\" | \"anxiety\" | \"anything\" | \"associates\" | \"attention\" | \"august\" | \"aw\" | \"back\" | \"bairn\" | \"bastard\" | \"bastards\" | \"betrayal\" | \"bomber\" | \"box\" | \"boy\" | \"brar\" | \"cab\" | \"case\" | \"ceiling\" | \"charges\" | \"church\" | \"conviction\" | \"cunt\" | \"cunts\" | \"days\" | \"dealer\" | \"deek\" | \"door\" | \"driver\" | \"drivers\" | \"earth\" | \"energy\" | \"eyes\" | \"feet\" | \"festival\" | \"fit\" | \"nothing\" | \"vermin\" | \"villain\" | \"yin\" | \"forefinger\" | \"form\" | \"friends\" | \"fucker\" | \"game\" | \"gear\" | \"gob\" | \"god\" | \"group\" | \"guy\" | \"guys\" | \"hall\" | \"hame\" | \"hand\" | \"handset\" | \"hassle\" | \"heid\" | \"hundred\" | \"jaykit\" | \"jaykits\" | \"junk\" | \"last\" | \"leith\" | \"lips\" | \"man\" | \"mate\" | \"minute\"| \"misery\" | \"mob\" | \"money\" | \"movies\" | \"neck\" | \"need\" | \"notice\" | \"one\" | \"pence\" | \"phase\" | \"picture\" | \"pish\" | \"plot\" | \"point\" | \"post\" | \"radge\" | \"radges\" | \"rank\" | \"rhythm\" | \"ride\" | \"saps\" | \"schemes\" | \"score\" | \"second\" | \"seriousness\" | \"shellsuits\" | \"shoap\" | \"show\" | \"sidekick\" | \"sighthill\" | \"sinews\" | \"size\" | \"squad\" | \"square\" | \"summer\" | \"sweat\" | \"taxi\" | \"taxis\" | \"telly\" | \"tension\" | \"testimonies\" | \"then\" | \"thighs\" | \"time\" | \"tod\" | \"tollcross\" | \"video\" | \"visage\" | \"voice\" | \"Walk\" | \"waste\"\n",
    "  Adv -> \"too\" | \"ready\" | \"straight\" | \"screaming\" | \"oot\" | \"sick\" | \"first\" | \"not\" | \"up\" | \"ay\" | \"doon\" | \"thegither\" | \"yet\" | \"also\" | \"back\" | \"breathlessly\" | \"deliberately\" | \"deliriously\" | \"desperately\" | \"else\" | \"even\" | \"ever\" | \"eywis\" | \"fuckin\" | \"heavily\" | \"here\" | \"incrementally\" | \"jist\" | \"just\" | \"nervously\" | \"never\" | \"nivir\" | \"no\" | \"now\" | \"oaf\" | \"off\" | \"once\" | \"only\" | \"probably\" | \"rather\" | \"real\" | \"really\" | \"sae\" | \"so\" | \"sure\" | \"thair\" | \"then\" | \"too\" | \"truly\" | \"usually\" | \"well\"\n",
    "  CC -> \"when\" | \"yet\" | \"while\" | \"and\" | \"as\" | \"because\" | \"but\" | \"fae\" | \"fi\" | \"fir\" | \"if\" | \"like\" | \"n\" | \"or\" | \"so\" | \"that\" | \"thit\" | \"though\"\n",
    "  InterJ -> \"taxi\" | \"aw\" | \"aye\" | \"fuckin\" | \"hi\"\n",
    "\"\"\")\n",
    "\n",
    "cfg_1_parser = nltk.RecursiveDescentParser(cfg_1)\n",
    "#\"yir\" in \"yir no feart ay they wee fuckin saps ur ye?\"  --> \"you are feart ay they wee fuckin saps ur ye?\"\n",
    "  #\"yuv\" See whit yuv done now, ya big-moothed cunt. --> See whit you have done nnow, ya big-moothed cunt. \n",
    "    #\"oafay\" (off of) in the original text is re-written as \"oaf\" (Adv) and \"ay\" (Prep). Compounds are broken up to simplify part-of-speech tagging.\n",
    "    \n",
    "#check_sentence(cfg_1_parser, 'the sweat wis lashing oaf ay sickboy')\n",
    "#\"sick boy\" and further pronouns composed with two words are simplifed by eliminating the space between the words. This is done to reduce ambiguity (since Welsh nicknames his character with names highly similar to NPs.)\n",
    "#check_sentence(cfg_1_parser, 'he wis trembling')\n",
    "#the semicolon has been replaced with a dot before \"he wis trembling\" to simplify the usage of semicolons. \n",
    "#check_sentence(cfg_1_parser, 'ah wis jist sitting thair focusing oan the telly tryin no tae notice the cunt')\n",
    "#commas in a long sentence are eliminated for the parser. \n",
    "#check_sentence(cfg_1_parser, 'he wis bringing me doon')\n",
    "#check_sentence(cfg_1_parser, 'ah tried tae keep ma attention oan the jeanclaudevandamme video')\n",
    "#check_sentence(cfg_1_parser, 'they started oaf wi an obligatory dramatic opening as happens in such movies')\n",
    "check_sentence(cfg_1_parser, 'then the next phase ay the picture involved building up the tension through introducing the dastardly villain and sticking the weak plot thegither')\n",
    "#check_sentence(cfg_1_parser, 'any minute now though auld jeanclaude is ready tae git doon tae some serious swedgin') #eliminated ready for now\n",
    "#((any minute) now). NP -> Det N Adv\n",
    "#the apostrophy s is modifed to be xx is. For the sake of simplicity.\n",
    "#check_sentence(cfg_1_parser, 'rents')\n",
    "#check_sentence(cfg_1_parser, 'ah have goat tae see mothersuperior')\n",
    "#ah've -> ah have. \n",
    "#ah have goat tae see mothersuperior, sickboy gasped, shaking his heid. Example of sentence broken up\n",
    "#check_sentence(cfg_1_parser, 'sickboy gasped shaking his heid')\n",
    "#check_sentence(cfg_1_parser, 'aw') #sentence broken up\n",
    "#check_sentence(cfg_1_parser, 'ah sais') \n",
    "#ah wanted the radge tae jist fuck off ootay ma visage, tae go oan his ain n jist leave us wi jeanclaude\n",
    "\n",
    "########\n",
    "\n",
    "#check_sentence(cfg_1_parser, 'ah wanted the radge oot ay ma visage tae go oan his ain n jist leave us wi jeanclaude') #example of sentence combined. Getting rid of \"tae jist fuck off\"\n",
    "   ##check_sentence(cfg_1_parser, 'oan the other hand ah would be gitting sick tae')  #at the moment, the before long at the end of the sentence is ignored. \n",
    "   ##check_sentence(cfg_1_parser, 'and if that cunt went n scored he would haud oot oan us')\n",
    "\n",
    "   ##check_sentence(cfg_1_parser, 'they call um sickboy no because he is eywis sick wi junk withdrawal but because he is just one sick cunt')\n",
    "   ##check_sentence(cfg_1_parser, 'let us fuckin go') #sentence split\n",
    "   ##check_sentence(cfg_1_parser, 'he snapped desperately')\n",
    "   ##check_sentence(cfg_1_parser, 'haud oan a second')\n",
    "   ##check_sentence(cfg_1_parser, 'ah wanted tae see jeanclaude smash up this arrogant fucker')\n",
    "#check_sentence(cfg_1_parser, 'ah wouldnae git tae watch it') \n",
    "\n",
    "#check_sentence(cfg_1_parser, 'ah would be too fucked by the time we goat back')\n",
    "#check_sentence(cfg_1_parser, 'and in any case it wid probably be a few days later')\n",
    "#check_sentence(cfg_1_parser, 'that meant ah wouldd git hit fir fuckin back charges fi the shoap oan a video ah hudnae even goat a deek at')\n",
    "  ##check_sentence(cfg_1_parser, 'ah have goat tae fuckin move') #eliminated \"man\" in the end to reduce ambig\n",
    "  ##check_sentence(cfg_1_parser, 'he shouts standing up')\n",
    "#check_sentence(cfg_1_parser, 'he moves ower tae the windae and rests against it breathing heavily looking like a hunted animal')\n",
    "  ##check_sentence(cfg_1_parser, 'there is nothing in his eyes but need')\n",
    "  ##check_sentence(cfg_1_parser, 'ah switched the box oaf at the handset')\n",
    "  ##check_sentence(cfg_1_parser, 'fuckin waste')\n",
    "#check_sentence(cfg_1_parser, 'that is aw it is')  #sentence split\n",
    "  ##check_sentence(cfg_1_parser, ' a fuckin waste')\n",
    "  ##check_sentence(cfg_1_parser, 'ah snarled at the cunt the fuckin irritating bastard')\n",
    "  ##check_sentence(cfg_1_parser, 'he flings back his heid n raises his eyes tae the ceiling')\n",
    "  ##check_sentence(cfg_1_parser, 'ah will gie ye the money tae git it oot') #deleted back from back oot\n",
    "\n",
    "#check_sentence(cfg_1_parser, 'is that aw yir sae fuckin moosey-faced aboot')\n",
    "  ##check_sentence(cfg_1_parser, 'fifty measley fuckin pence oot ay ritz')\n",
    "#check_sentence(cfg_1_parser, 'this cunt has a wey ay makin ye feel a real petty trivial bastard')\n",
    "#check_sentence(cfg_1_parser, 'that is no the fuckin point')  #sentence split\n",
    "  ##check_sentence(cfg_1_parser, 'ah sais withoot conviction') #deleted but from but withoot conviction\n",
    "  ##check_sentence(cfg_1_parser, 'aye')\n",
    "#check_sentence(cfg_1_parser, 'The point is ah'm really fuckin sufferin here, n ma so-called mate's draggin his feet deliberately, lovin every fuckin minute ay it')\n",
    "#check_sentence(cfg_1_parser, 'His eyes seem the size ay fitba's n look hostile, yet pleadin at the same time')\n",
    "  ##check_sentence(cfg_1_parser, 'poignant testimonies tae ma supposed betrayal')\n",
    "#check_sentence(cfg_1_parser, 'If ah ever live long enough tae huv a bairn, ah hope it never looks at us like Sick Boy does')#check_sentence(cfg_1_parser, 'The cunt is irresistible oan this form')\n",
    "  ##check_sentence(cfg_1_parser, 'ah wis not')  #wisnae -> wis nae -> wis not. Not added to vocab\n",
    "  ##check_sentence(cfg_1_parser, 'ah protested')\n",
    "#check_sentence(cfg_1_parser, 'fling yir fuckin jaykit oan well')\n",
    "#check_sentence(cfg_1_parser, 'at the fit ay the Walk thir wir nae taxis')\n",
    "  ##check_sentence(cfg_1_parser, 'they only congregated here when ye didnae need them')\n",
    "#check_sentence(cfg_1_parser, 'supposed tae be August, but ah'm fuckin freezing ma baws oaf here')\n",
    "#check_sentence(cfg_1_parser, 'ah am no sick yet but it is in the fuckin post')\n",
    "#check_sentence(cfg_1_parser, 'that is fir sure')\n",
    "   ##check_sentence(cfg_1_parser, 'supposed tae be a rank')\n",
    "   ##check_sentence(cfg_1_parser, 'supposed tae be a fuckin taxi rank')   \n",
    "   ##check_sentence(cfg_1_parser, 'nivir fuckin git one in the summer')\n",
    "#check_sentence(cfg_1_parser, 'up cruising fat rich festival cunts too fuckin lazy tae walk a hundred fuckin yards fae one poxy church hall tae another fir thir fuckin show')\n",
    "  ##check_sentence(cfg_1_parser, 'taxi drivers')\n",
    "  ##check_sentence(cfg_1_parser, 'money-grabbin bastards')\n",
    "#check_sentence(cfg_1_parser, 'sickboy muttered deliriously and breathlessly tae hissel, eyes bulging and sinews in his neck straining as his heid craned up leithwalk ')\n",
    "  ##check_sentence(cfg_1_parser, 'at last one came')\n",
    "#check_sentence(cfg_1_parser, 'there were a group ay young guys in shellsuits n bomber jaykits whae had been standin thair longer than us')\n",
    "  ##check_sentence(cfg_1_parser, 'ah doubt if sickboy even saw them')\n",
    "\n",
    "  ##check_sentence(cfg_1_parser, 'he charged screaming intae the middle ay the Walk') #moved the adverb screaming behind the verb, to accomedate for the the VP -> Adv VP (not VP -> VP Adv). Deleted \"oot\".    #straight intae the middle ay the walk causes a few too many trees. \n",
    "  #first time i specifed capital letters, to reduce ambiguity of Walk (street) and walk. \n",
    "\n",
    "  ##check_sentence(cfg_1_parser, 'taxi')\n",
    "  ##check_sentence(cfg_1_parser, 'hi ')\n",
    "  ##check_sentence(cfg_1_parser, 'whit is the score')\n",
    "#check_sentence(cfg_1_parser, 'one guy asks in a black purple and aqua shell-suit wi a flat-top') \n",
    "  ##check_sentence(cfg_1_parser, 'git tae fuck') \n",
    "  ##check_sentence(cfg_1_parser, 'we wir here first')\n",
    "  ##check_sentence(cfg_1_parser, 'sickboy sais opening the taxi door')\n",
    "#check_sentence(cfg_1_parser, 'Thir's another yin comin'）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n",
    "#check_sentence(cfg_1_parser, ''）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a jackjones will haud\n",
      "a jackjones will gitting\n",
      "a jackjones will supposed\n",
      "a jackjones will opening\n",
      "a jackjones will notice\n",
      "a jackjones will add\n",
      "a jackjones will asks\n",
      "a jackjones will based\n",
      "a jackjones will baws\n",
      "a jackjones will beating\n",
      "a jackjones will breathing\n",
      "a jackjones will bringing\n",
      "a jackjones will building\n",
      "a jackjones will bulging\n",
      "a jackjones will call\n",
      "a jackjones will called\n",
      "a jackjones will came\n",
      "a jackjones will charged\n",
      "a jackjones will comin\n",
      "a jackjones will congregated\n",
      "a jackjones will covered\n",
      "a jackjones will craned\n",
      "a jackjones will done\n",
      "a jackjones will doubt\n",
      "a jackjones will draggin\n",
      "a jackjones will emphasise\n",
      "a jackjones will faster\n",
      "a jackjones will feel\n",
      "a jackjones will fling\n",
      "a jackjones will flings\n",
      "a jackjones will focusing\n",
      "a jackjones will freezing\n",
      "a jackjones will harassing\n",
      "a jackjones will hing\n",
      "a jackjones will introducing\n",
      "a jackjones will knowing\n",
      "a jackjones will lashing\n",
      "a jackjones will looking\n",
      "a jackjones will saying\n",
      "a jackjones will shaking\n",
      "a jackjones will sitting\n",
      "a jackjones will standing\n",
      "a jackjones will sticking\n",
      "a jackjones will straining\n",
      "a jackjones will suffering\n",
      "a jackjones will trembling\n",
      "a jackjones will willing\n",
      "a jackjones will gittin\n",
      "a jackjones will lovin\n",
      "a jackjones will makin\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "for sentence in generate(cfg_1, depth=4, n=50):\n",
    "     print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
